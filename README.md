# Knowledge Graph Constructor

A modular system for extracting knowledge graphs from text using multiple LLM backends. Supports **Gemini API**, **Ollama**, and **LM Studio** with a unified client abstraction interface.

## âœ¨ Features

### Core Capabilities
- **Multi-Backend LLM Support**: Clean abstraction layer for Gemini API (cloud), Ollama (local), and LM Studio (local)
- **Knowledge Graph Extraction**: Extract structured triples (head-relation-tail) from unstructured text
- **Graph Augmentation**: Iterative refinement strategies to improve graph connectivity
- **Multiple Export Formats**: GraphML (NetworkX compatible), JSON, with extensible converter system
- **Interactive Visualizations**: Plotly-based network graphs and entity highlighting with dark mode support

### Data Handling
- **Multiple Input Formats**: CSV, JSON, and JSONL file support with auto-detection
- **Batch Processing**: Process large datasets with progress tracking
- **Domain-Specific Extraction**: Customizable prompts and examples per knowledge domain

---

## ğŸš€ Quick Start

### Installation

```bash
pip install -r requirements.txt
```

### Prerequisites

- Python 3.11+
- **For Gemini**: API key from [Google AI Studio](https://makersuite.google.com/app/apikey)
- **For Ollama**: [Ollama](https://ollama.ai/) installed and running locally
- **For LM Studio**: [LM Studio](https://lmstudio.ai/) server running with a loaded model

### Basic Usage

```bash
# Extract with Gemini
python -m src extract --input data.jsonl --domain legal --client gemini

# Extract with Ollama
python -m src extract --input data.jsonl --domain default --client ollama --model llama3.1

# Extract with LM Studio
python -m src extract --input data.csv --domain legal --client lmstudio --base-url http://localhost:1234/v1
```

---

## ğŸ“‹ Available Commands

| Command | Description |
|---------|-------------|
| `extract` | Extract knowledge graph triples from text (Step 1) |
| `augment connectivity` | Reduce disconnected graph components (Step 2) |
| `convert` | Convert JSON triples to GraphML format |
| `visualize network` | Create interactive network visualizations |
| `visualize extraction` | Create text visualizations with entity highlights |
| `list domains` | List available knowledge domains |
| `list clients` | List available LLM client types |

### Step 1: Extract

```bash
python -m src extract \
  --input data.jsonl \
  --domain legal \
  --client gemini \
  --output-dir outputs/kg_extraction \
  --limit 10
```

**Options:**
- `--input, -i`: Input file (JSONL, JSON, or CSV)
- `--domain, -d`: Knowledge domain (default, legal)
- `--client, -c`: LLM backend (gemini, ollama, lmstudio)
- `--model`: Model identifier (optional, uses defaults)
- `--output-dir, -o`: Output directory
- `--text-field`: Field containing text (default: "text")
- `--id-field`: Field for record IDs (default: "id")
- `--limit`: Maximum records to process
- `--temperature`: LLM temperature (default: 0.0)
- `--workers`: Max parallel workers
- `--timeout`: Request timeout in seconds

### Step 2: Augment

```bash
python -m src augment connectivity \
  --input data.jsonl \
  --domain legal \
  --client gemini \
  --max-iterations 3
```

**Options:**
- `--max-iterations`: Max refinement iterations (default: 3)
- All extraction options apply

### Convert

```bash
python -m src convert --input outputs/extracted_json --output outputs/graphml
```

### Visualize

```bash
# Network visualization
python -m src visualize network --input outputs/graphml --dark-mode

# Entity extraction visualization
python -m src visualize extraction --input data.jsonl --triples outputs/extracted_json
```

---

## ğŸ“ Output Structure

```
outputs/kg_extraction/
â”œâ”€â”€ extracted_json/       # JSON triples with metadata
â”œâ”€â”€ graphml/              # NetworkX-compatible GraphML files
â””â”€â”€ visualizations/       # Interactive HTML visualizations
```

### JSON Triple Format

```json
{
  "head": "Entity 1",
  "relation": "relates to",
  "tail": "Entity 2",
  "inference": "explicit",
  "char_start": 0,
  "char_end": 25,
  "extraction_text": "Entity 1 relates to Entity 2"
}
```

---

## ğŸ”§ Architecture

### Module Structure

```
src/
â”œâ”€â”€ __init__.py              # Package initialization
â”œâ”€â”€ __main__.py              # CLI entry point (Typer-based)
â”œâ”€â”€ builder/                 # Graph construction
â”‚   â”œâ”€â”€ extraction.py        # Initial triple extraction
â”‚   â””â”€â”€ augmentation.py      # Augmentation strategies (connectivity, etc.)
â”œâ”€â”€ clients/                 # LLM client abstraction
â”‚   â”œâ”€â”€ base.py              # BaseLLMClient interface
â”‚   â”œâ”€â”€ config.py            # ClientConfig dataclass
â”‚   â”œâ”€â”€ factory.py           # ClientFactory for client creation
â”‚   â””â”€â”€ providers/           # Provider implementations
â”‚       â”œâ”€â”€ gemini.py        # Gemini API client
â”‚       â”œâ”€â”€ ollama.py        # Ollama client
â”‚       â””â”€â”€ lmstudio.py      # LM Studio client
â”œâ”€â”€ converters/              # Output format converters
â”‚   â””â”€â”€ graphml.py           # JSON â†’ GraphML converter
â”œâ”€â”€ datasets/                # Input format loaders
â”‚   â””â”€â”€ __init__.py          # CSV, JSON, JSONL loaders
â”œâ”€â”€ domains/                 # Knowledge domain definitions
â”‚   â”œâ”€â”€ base.py              # KnowledgeDomain base class
â”‚   â”œâ”€â”€ registry.py          # Domain registration
â”‚   â”œâ”€â”€ models.py            # Triple, Example Pydantic models
â”‚   â”œâ”€â”€ default/             # Default domain resources
â”‚   â””â”€â”€ legal/               # Legal domain resources
â””â”€â”€ visualization/           # Visualization engines
    â”œâ”€â”€ network_viz.py       # Plotly network graphs
    â””â”€â”€ entity_viz.py        # Entity text highlighting
```

### Client Abstraction

All LLM backends implement the `BaseLLMClient` interface:

```python
from src.clients import ClientFactory, ClientConfig

config = ClientConfig(
    client_type="gemini",
    model_id="gemini-2.0-flash-exp",
    api_key="your-key"
)
client = ClientFactory.create(config)

result = client.extract(
    text="Sample document text...",
    prompt_description="Extract entities and relationships"
)
```

### Domain System

Domains define prompts and examples for specific knowledge areas:

```python
from src.domains import get_domain, list_available_domains

# List available domains
print(list_available_domains())  # ['default', 'legal']

# Get domain with resources
domain = get_domain("legal")
prompt = domain.extraction.prompt
examples = domain.extraction.examples
```

---

## ğŸ› ï¸ Extensibility (Agent Skills)

This repository includes Claude agent skills for guided extensibility:

| Skill | Description |
|-------|-------------|
| `add-llm-client` | Add new LLM provider (e.g., Anthropic, OpenAI, Groq) |
| `add-domain` | Create new knowledge domain with prompts and examples |
| `add-augmentation-strategy` | Add graph refinement strategy (e.g., enrichment, summarization) |
| `add-converter` | Add output format converter (e.g., CSV, RDF, JSON-LD) |
| `add-dataset-format` | Add input format loader (e.g., Parquet, Excel) |
| `add-visualization` | Add visualization type (e.g., timeline, hierarchical) |

### Skill Locations

Skills are located in `.agent/skills/` and provide step-by-step guides with:
- Architecture diagrams
- Complete code implementations
- CLI integration patterns
- Unit and integration tests
- Error handling reference

---

## ğŸ—‚ï¸ Supported Domains

| Domain | Description | Resources |
|--------|-------------|-----------|
| `default` | Generic entity-relationship extraction | Open/constrained prompts, examples |
| `legal` | Legal document analysis | Legal-specific prompts, entity types |

### Domain Structure

```
src/domains/<domain>/
â”œâ”€â”€ __init__.py                 # Domain class with @domain decorator
â”œâ”€â”€ extraction/
â”‚   â”œâ”€â”€ prompt_open.txt         # Open extraction prompt
â”‚   â”œâ”€â”€ prompt_constrained.txt  # Type-constrained extraction
â”‚   â””â”€â”€ examples.json           # Few-shot examples
â”œâ”€â”€ augmentation/
â”‚   â””â”€â”€ connectivity/           # Augmentation strategy resources
â”‚       â”œâ”€â”€ prompt.txt
â”‚       â””â”€â”€ examples.json
â””â”€â”€ schema.json                 # Entity/relation type constraints (optional)
```

---

## ğŸ”Œ LLM Clients

| Client | Type | Default Model | Requirements |
|--------|------|---------------|--------------|
| `gemini` | Cloud | gemini-2.0-flash | `LANGEXTRACT_API_KEY` env var |
| `ollama` | Local | llama3.1 | Ollama running on localhost:11434 |
| `lmstudio` | Local | (loaded model) | LM Studio server running |

### Environment Variables

```bash
export LANGEXTRACT_API_KEY="your-gemini-api-key"
```

---

## ğŸ“Š Visualization Options

### Network Visualization

- **Layouts**: spring, circular, kamada_kawai, shell
- **Dark Mode**: Premium dark theme with glassmorphism
- **Interactive**: Hover tooltips, zoom, pan

### Entity Visualization

- **Text Highlighting**: Entity spans with color coding
- **Animations**: Smooth highlight transitions
- **Grouping**: By entity type or relation

---

## ğŸ§ª Testing

```bash
# Quick validation
python -m src extract --input data/sample.jsonl --domain default --limit 1

# List available resources
python -m src list domains
python -m src list clients
```

---

## ğŸ“– Documentation

- [Unified Extraction Guide](docs/UNIFIED_EXTRACTION_GUIDE.md) - Complete system documentation
- [Agent Skills](.agent/skills/) - Extensibility guides for developers

---

## ğŸ“„ License

See LICENSE file for details.
